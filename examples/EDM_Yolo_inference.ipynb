{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Inference YOLOv8m\n",
    "\n",
    "Load model from [Ultralitics](https://github.com/qubvel-org/segmentation_models.pytorch) and process some test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import onnxruntime as ort\n",
    "import typing as tp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIR = '../test_images'\n",
    "NN_THRESHOLD = 0.7\n",
    "BATCH_SIZE = 1\n",
    "MODEL_ONNX_FILE = '../models/YOLOv11m-seg.onnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nms_pytorch(P: torch.tensor ,thresh_iou: float):\n",
    "    \"\"\"\n",
    "    Apply non-maximum suppression to avoid detecting too many\n",
    "    overlapping bounding boxes for a given object.\n",
    "    Args:\n",
    "        boxes: (tensor) The location preds for the image \n",
    "            along with the class predscores, Shape: [num_boxes,5].\n",
    "        thresh_iou: (float) The overlap thresh for suppressing unnecessary boxes.\n",
    "    Returns:\n",
    "        A list of filtered boxes, Shape: [ , 5]\n",
    "    \"\"\"\n",
    " \n",
    "    # we extract coordinates for every \n",
    "    # prediction box present in P\n",
    "    x1 = P[:, 0]\n",
    "    y1 = P[:, 1]\n",
    "    x2 = P[:, 2]\n",
    "    y2 = P[:, 3]\n",
    " \n",
    "    # we extract the confidence scores as well\n",
    "    scores = P[:, 4]\n",
    " \n",
    "    # calculate area of every block in P\n",
    "    areas = (x2 - x1) * (y2 - y1)\n",
    "     \n",
    "    # sort the prediction boxes in P\n",
    "    # according to their confidence scores\n",
    "    order = scores.argsort()\n",
    " \n",
    "    # initialise an empty list for \n",
    "    # filtered prediction boxes\n",
    "    keep = []\n",
    "     \n",
    " \n",
    "    while len(order) > 0:\n",
    "         \n",
    "        # extract the index of the \n",
    "        # prediction with highest score\n",
    "        # we call this prediction S\n",
    "        idx = order[-1]\n",
    " \n",
    "        # push S in filtered predictions list\n",
    "        keep.append(P[idx])\n",
    " \n",
    "        # remove S from P\n",
    "        order = order[:-1]\n",
    " \n",
    "        # sanity check\n",
    "        if len(order) == 0:\n",
    "            break\n",
    "         \n",
    "        # select coordinates of BBoxes according to \n",
    "        # the indices in order\n",
    "        xx1 = torch.index_select(x1,dim = 0, index = order)\n",
    "        xx2 = torch.index_select(x2,dim = 0, index = order)\n",
    "        yy1 = torch.index_select(y1,dim = 0, index = order)\n",
    "        yy2 = torch.index_select(y2,dim = 0, index = order)\n",
    " \n",
    "        # find the coordinates of the intersection boxes\n",
    "        xx1 = torch.max(xx1, x1[idx])\n",
    "        yy1 = torch.max(yy1, y1[idx])\n",
    "        xx2 = torch.min(xx2, x2[idx])\n",
    "        yy2 = torch.min(yy2, y2[idx])\n",
    " \n",
    "        # find height and width of the intersection boxes\n",
    "        w = xx2 - xx1\n",
    "        h = yy2 - yy1\n",
    "         \n",
    "        # take max with 0.0 to avoid negative w and h\n",
    "        # due to non-overlapping boxes\n",
    "        w = torch.clamp(w, min=0.0)\n",
    "        h = torch.clamp(h, min=0.0)\n",
    " \n",
    "        # find the intersection area\n",
    "        inter = w*h\n",
    " \n",
    "        # find the areas of BBoxes according the indices in order\n",
    "        rem_areas = torch.index_select(areas, dim = 0, index = order) \n",
    " \n",
    "        # find the union of every prediction T in P\n",
    "        # with the prediction S\n",
    "        # Note that areas[idx] represents area of S\n",
    "        union = (rem_areas - inter) + areas[idx]\n",
    "         \n",
    "        # find the IoU of every prediction in P with S\n",
    "        IoU = inter / union\n",
    " \n",
    "        # keep the boxes with IoU less than thresh_iou\n",
    "        mask = IoU < thresh_iou\n",
    "        order = order[mask]\n",
    "     \n",
    "    return keep\n",
    "\n",
    "\n",
    "def onnx_preprocessing(\n",
    "    image: np.ndarray,\n",
    "    image_size: tp.Tuple[int, int] = (224, 224),\n",
    ") -> np.ndarray:\n",
    "    # resize\n",
    "    image = cv2.resize(image.copy(), image_size, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    # normalize\n",
    "    mean = np.array((0.485, 0.456, 0.406), dtype=np.float32) * 255.0\n",
    "    std = np.array((0.229, 0.224, 0.225), dtype=np.float32) * 255.0\n",
    "    denominator = np.reciprocal(std, dtype=np.float32)\n",
    "    image = image.astype(np.float32)\n",
    "    image -= mean\n",
    "    image *= denominator\n",
    "\n",
    "    # transpose\n",
    "    image = image.transpose((2, 0, 1))[None]\n",
    "    return image\n",
    "\n",
    "\n",
    "def intersection(box1,box2):\n",
    "    box1_x1,box1_y1,box1_x2,box1_y2 = box1[:4]\n",
    "    box2_x1,box2_y1,box2_x2,box2_y2 = box2[:4]\n",
    "    x1 = max(box1_x1,box2_x1)\n",
    "    y1 = max(box1_y1,box2_y1)\n",
    "    x2 = min(box1_x2,box2_x2)\n",
    "    y2 = min(box1_y2,box2_y2)\n",
    "    return (x2-x1)*(y2-y1) \n",
    "\n",
    "\n",
    "def union(box1,box2):\n",
    "    box1_x1,box1_y1,box1_x2,box1_y2 = box1[:4]\n",
    "    box2_x1,box2_y1,box2_x2,box2_y2 = box2[:4]\n",
    "    box1_area = (box1_x2-box1_x1)*(box1_y2-box1_y1)\n",
    "    box2_area = (box2_x2-box2_x1)*(box2_y2-box2_y1)\n",
    "    return box1_area + box2_area - intersection(box1,box2)\n",
    "\n",
    "\n",
    "def iou(box1,box2):\n",
    "    return intersection(box1,box2)/union(box1,box2)\n",
    "\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "\n",
    "def binary_mask_iou(\n",
    "        mask1: np.array,\n",
    "        mask2: np.array,\n",
    "        label_value: int = 1,\n",
    ") -> float:\n",
    "    mask1_area = np.count_nonzero(mask1 == label_value)\n",
    "    mask2_area = np.count_nonzero(mask2 == label_value)\n",
    "    intersection = np.count_nonzero(\n",
    "        np.logical_and(mask1==label_value,  mask2==label_value)\n",
    "    )\n",
    "    return intersection / (mask1_area + mask2_area-intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Process annotations data\n",
    "d_path_annot = '../IoU_test/annotations/balanced_test.json'\n",
    "d_path_images = '../IoU_test/images'\n",
    "\n",
    "processed_data = {\n",
    "    'Id': [],\n",
    "    'image_path': [],\n",
    "    'semantic_masks': [],\n",
    "    'granules_number': []\n",
    "}\n",
    "\n",
    "with open(d_path_annot, 'r', encoding=\"utf-8\") as json_file:\n",
    "    json_data_dir = json.load(json_file)\n",
    "    # Process image data\n",
    "    for image_inf in tqdm(json_data_dir['images'], desc=\"Process images: \"):\n",
    "        real_img_id = image_inf['id']\n",
    "        for k in processed_data:\n",
    "            processed_data[k].append([])\n",
    "        processed_data['Id'][-1] = real_img_id\n",
    "        img_name = image_inf['file_name'].split('/')[-1]\n",
    "        img_path = os.path.join(\n",
    "            d_path_images, img_name\n",
    "        )\n",
    "        processed_data['image_path'][-1] = str(img_path)\n",
    "        SIZE = (image_inf['height'], image_inf['width'], 3)\n",
    "        processed_data['semantic_masks'][-1] = np.zeros(SIZE[:2], dtype=np.uint8)\n",
    "        processed_data['granules_number'][-1] = 0\n",
    "\n",
    "with open(d_path_annot, 'r') as json_file:\n",
    "    json_data_dir = json.load(json_file)\n",
    "    image_id_old = ''\n",
    "    skipped_counter = 1\n",
    "    morph_kernel = cv2.getStructuringElement(\n",
    "        cv2.MORPH_ELLIPSE, (3, 3)\n",
    "    )\n",
    "\n",
    "    for annotation_data in tqdm(\n",
    "        json_data_dir['annotations'], desc=\"Process annotations: \"\n",
    "    ):\n",
    "        # Data may be numerated to image of have through numeration\n",
    "        process_image_id = annotation_data['image_id']\n",
    "\n",
    "        image_data_indx = processed_data['Id'].index(process_image_id)\n",
    "        label = annotation_data['category_id']\n",
    "        # Process each granule\n",
    "        for point_i, point in enumerate(annotation_data['segmentation']):\n",
    "            if isinstance(point, list):\n",
    "                point_xy = [\n",
    "                    [point[j], point[j + 1]] for j in\n",
    "                    range(0, len(point), 2)\n",
    "                ]\n",
    "                cnt = np.array(point_xy).reshape((-1, 1, 2)).astype(\n",
    "                    np.int32\n",
    "                )\n",
    "                if len(cnt) < 3:  # bad contour\n",
    "                    print('Cnt is bad')\n",
    "                    continue\n",
    "\n",
    "                single_mask = np.zeros((480, 480), dtype=np.uint8)\n",
    "                _ = cv2.drawContours(\n",
    "                    single_mask,\n",
    "                    [cnt], -1, label, cv2.FILLED\n",
    "                )\n",
    "                processed_data['semantic_masks'][image_data_indx][single_mask != 0] = label\n",
    "                x, y, w, h = annotation_data[\"bbox\"]\n",
    "                processed_data['granules_number'][image_data_indx] += 1\n",
    "            else:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "providers = [\n",
    "    'CUDAExecutionProvider',\n",
    "    'CPUExecutionProvider',\n",
    "]\n",
    "\n",
    "ort_session = ort.InferenceSession(\n",
    "    MODEL_ONNX_FILE,\n",
    "    providers=providers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a YOLO model\n",
    "for image_path in list(os.walk(IMAGE_DIR + '/preprocess/'))[0][2]:\n",
    "    test_image = cv2.imread(IMAGE_DIR + '/preprocess/' + image_path)\n",
    "    test_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    onnx_input = onnx_preprocessing(\n",
    "        test_image,\n",
    "        image_size=(480, 480)\n",
    "    )\n",
    "    onnx_input = np.concatenate([onnx_input] * BATCH_SIZE)\n",
    "    ort_inputs = {ort_session.get_inputs()[0].name: onnx_input}\n",
    "    ort_outputs = ort_session.run(None, ort_inputs)\n",
    "    \n",
    "    prediction = ort_outputs[0]\n",
    "    number_of_classes = 1\n",
    "    mask_index = 4 + number_of_classes\n",
    "    prediction = prediction[0].transpose()\n",
    "    pass_boxes_mask = prediction[:, 4:mask_index] >= NN_THRESHOLD\n",
    "    pass_data = []\n",
    "    for xi, x in enumerate(prediction):  # image index, image inference\n",
    "        if pass_boxes_mask[xi][0]:\n",
    "            xc, yc, w, h, prob = x[:5]\n",
    "            x1 = xc - w / 2\n",
    "            y1 = yc - h / 2\n",
    "            x2 = xc + w / 2\n",
    "            y2 = yc + h / 2\n",
    "            masks = x[5:]\n",
    "            pass_data.append(np.array([x1, y1, x2, y2, prob] + list(masks)))\n",
    "\n",
    "    pass_data_result = []\n",
    "    pass_data.sort(key=lambda x: x[4], reverse=True)\n",
    "    while len(pass_data) > 0:\n",
    "        pass_data_result.append(pass_data[0])\n",
    "        pass_data = [\n",
    "            box for box in pass_data if iou(\n",
    "                box[:4], pass_data[0][:4]\n",
    "            ) < NN_THRESHOLD\n",
    "        ]\n",
    "\n",
    "    green_masks = np.zeros(test_image.shape, dtype=np.uint8)\n",
    "    if pass_data_result:\n",
    "        pass_results = np.array(pass_data_result)\n",
    "        masks = pass_results[:, 5:]\n",
    "        boxes = pass_results[:, :5]\n",
    "\n",
    "        mask_len, mask_h, mask_w = ort_outputs[1].shape[1:]\n",
    "        output1 = ort_outputs[1][0].reshape(\n",
    "            mask_len, mask_h * mask_w\n",
    "        )\n",
    "        masks = masks @ output1  # (n, 32) (32, 25600)\n",
    "\n",
    "        for bbox_i, bbox in enumerate(pass_data_result):\n",
    "            _ = cv2.rectangle(\n",
    "                    test_image,\n",
    "                    (int(bbox[0]), int(bbox[1])),\n",
    "                    (int(bbox[2]), int(bbox[3])),\n",
    "                    (255,0,0),\n",
    "                    2\n",
    "                )\n",
    "\n",
    "            mask = masks[bbox_i].reshape(mask_h, mask_w)\n",
    "            mask = sigmoid(mask)\n",
    "            mask = (\n",
    "                           mask > NN_THRESHOLD\n",
    "                   ).astype('uint8') * 255\n",
    "            mask_x1 = round(bbox[0] / test_image.shape[0] * mask_w)\n",
    "            mask_y1 = round(bbox[1] / test_image.shape[1] * mask_h)\n",
    "            mask_x2 = round(bbox[2] / test_image.shape[0] * mask_w)\n",
    "            mask_y2 = round(bbox[3] / test_image.shape[1] * mask_h)\n",
    "\n",
    "            submask = np.zeros((mask_w, mask_h), np.uint8)\n",
    "            submask[mask_y1:mask_y2, mask_x1:mask_x2] = 255\n",
    "\n",
    "            # compute the bitwise AND using the mask\n",
    "            masked_mask = cv2.bitwise_and(mask, mask, mask=submask)\n",
    "            # Resize mask directly to the bounding box size\n",
    "            mask_resized = cv2.resize(\n",
    "                masked_mask,\n",
    "                (test_image.shape[0], test_image.shape[1]),\n",
    "                interpolation=cv2.INTER_LINEAR\n",
    "            )\n",
    "            mask_resized[mask_resized > 200] = 255\n",
    "            mask_resized[mask_resized <= 200] = 0\n",
    "\n",
    "            green_masks[:,:,0][mask_resized>0] = 61\n",
    "            green_masks[:,:,1][mask_resized>0] = 142\n",
    "            green_masks[:,:,2][mask_resized>0] = 48\n",
    "\n",
    "    test_image = cv2.addWeighted(test_image, 0.6, green_masks, 0.4, 0)\n",
    "    cv2.imwrite(IMAGE_DIR + f'/final/yolov8m_{int(NN_THRESHOLD*10)}_' + image_path, cv2.cvtColor(test_image, cv2.COLOR_RGB2BGR))\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    _ = ax.imshow(test_image, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_granules_det = []\n",
    "total_iou = []\n",
    "\n",
    "for image_i, image_path in enumerate(tqdm(processed_data['image_path'])):\n",
    "    test_image = cv2.imread(image_path)\n",
    "    test_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    gt_mask = processed_data['semantic_masks'][image_i]\n",
    "\n",
    "    onnx_input = onnx_preprocessing(\n",
    "        test_image,\n",
    "        image_size=(480, 480)\n",
    "    )\n",
    "    onnx_input = np.concatenate([onnx_input] * BATCH_SIZE)\n",
    "    ort_inputs = {ort_session.get_inputs()[0].name: onnx_input}\n",
    "    ort_outputs = ort_session.run(None, ort_inputs)\n",
    "\n",
    "    prediction = ort_outputs[0]\n",
    "    number_of_classes = 1\n",
    "    mask_index = 4 + number_of_classes\n",
    "    prediction = prediction[0].transpose()\n",
    "    pass_boxes_mask = prediction[:, 4:mask_index] >= NN_THRESHOLD\n",
    "    pass_data = []\n",
    "    for xi, x in enumerate(prediction):  # image index, image inference\n",
    "        if pass_boxes_mask[xi][0]:\n",
    "            xc, yc, w, h, prob = x[:5]\n",
    "            x1 = xc - w / 2\n",
    "            y1 = yc - h / 2\n",
    "            x2 = xc + w / 2\n",
    "            y2 = yc + h / 2\n",
    "            masks = x[5:]\n",
    "            pass_data.append(np.array([x1, y1, x2, y2, prob] + list(masks)))\n",
    "\n",
    "    pass_data_result = []\n",
    "    pass_data.sort(key=lambda x: x[4], reverse=True)\n",
    "    while len(pass_data) > 0:\n",
    "        pass_data_result.append(pass_data[0])\n",
    "        pass_data = [\n",
    "            box for box in pass_data if iou(\n",
    "                box[:4], pass_data[0][:4]\n",
    "            ) < NN_THRESHOLD\n",
    "        ]\n",
    "\n",
    "    pass_results = np.array(pass_data_result)\n",
    "    if pass_results.size == 0:\n",
    "        total_granules_det.append(0)\n",
    "        total_iou.append(0)\n",
    "        continue\n",
    "    masks = pass_results[:, 5:]\n",
    "    boxes = pass_results[:, :5]\n",
    "\n",
    "    mask_len, mask_h, mask_w = ort_outputs[1].shape[1:]\n",
    "    output1 = ort_outputs[1][0].reshape(\n",
    "        mask_len, mask_h * mask_w\n",
    "    )\n",
    "    masks = masks @ output1  # (n, 32) (32, 25600)\n",
    "\n",
    "    pr_mask = np.zeros(test_image.shape[:2], dtype=np.uint8)\n",
    "    for bbox_i, bbox in enumerate(pass_data_result):\n",
    "        mask = masks[bbox_i].reshape(mask_h, mask_w)\n",
    "        mask = sigmoid(mask)\n",
    "        mask = (\n",
    "                       mask > NN_THRESHOLD\n",
    "               ).astype('uint8') * 255\n",
    "        mask_x1 = round(bbox[0] / test_image.shape[0] * mask_w)\n",
    "        mask_y1 = round(bbox[1] / test_image.shape[1] * mask_h)\n",
    "        mask_x2 = round(bbox[2] / test_image.shape[0] * mask_w)\n",
    "        mask_y2 = round(bbox[3] / test_image.shape[1] * mask_h)\n",
    "\n",
    "        submask = np.zeros((mask_w, mask_h), np.uint8)\n",
    "        submask[mask_y1:mask_y2, mask_x1:mask_x2] = 255\n",
    "\n",
    "        # compute the bitwise AND using the mask\n",
    "        masked_mask = cv2.bitwise_and(mask, mask, mask=submask)\n",
    "        # Resize mask directly to the bounding box size\n",
    "        mask_resized = cv2.resize(\n",
    "            masked_mask,\n",
    "            (test_image.shape[0], test_image.shape[1]),\n",
    "            interpolation=cv2.INTER_LINEAR\n",
    "        )\n",
    "        mask_resized[mask_resized > 200] = 255\n",
    "        mask_resized[mask_resized <= 200] = 0\n",
    "\n",
    "        pr_mask[mask_resized>0] = 1\n",
    "    total_granules_det.append(len(pass_data_result))\n",
    "    total_iou.append(binary_mask_iou(gt_mask, pr_mask))\n",
    "\n",
    "\n",
    "granules_deviation = np.abs((np.array(total_granules_det) - np.array(processed_data['granules_number']))) / np.array(processed_data['granules_number']) * 100\n",
    "granules_detected = (np.array(total_granules_det) / np.array(processed_data['granules_number'])) * 100\n",
    "\n",
    "\n",
    "print(f\"Median and Average IoU for all dataset = {np.median(total_iou)} VS {np.average(total_iou)}, disp = {np.std(total_iou)}\")\n",
    "print(f\"Median and Average granules devianion for all dataset = {np.median(granules_deviation)} VS {np.average(granules_deviation)}, disp = {np.std(granules_deviation)}\")\n",
    "print(f\"Median and Average granules detected for all dataset = {np.median(granules_detected)} VS {np.average(granules_deviation)}, disp = {np.std(granules_detected)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

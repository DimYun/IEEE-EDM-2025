{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Models inference speed test\n",
    "\n",
    "Scripts for measure inference tests for 480x480 pxl tile\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from curses import wrapper\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from os import path\n",
    "import sys\n",
    "sys.path.append(path.abspath('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import onnxruntime as ort\n",
    "\n",
    "import typing as tp\n",
    "from typing import Any, Tuple\n",
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "from mmdet.apis import init_detector, inference_detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(\n",
    "    model: Any,\n",
    "    input_shape: Tuple[int] = (1, 1, 224, 224),\n",
    "    nwarmup: int = 50,\n",
    "    nruns: int = 10000,  # 2000\n",
    "    print_step: int = 1000,  # 500\n",
    "    prefiks: str = '',\n",
    "):\n",
    "    input_data = np.random.rand(*input_shape).astype(np.float32)\n",
    "\n",
    "    print(\"Warm up ...\")\n",
    "    for _ in range(nwarmup):\n",
    "        input_data = np.random.rand(*input_shape).astype(np.float32)\n",
    "        features = model.predict(input_data)\n",
    "\n",
    "    print(\"Start timing ...\")\n",
    "    timings = []\n",
    "    for i in range(1, nruns + 1):\n",
    "        input_data = np.random.rand(*input_shape).astype(np.float32)\n",
    "        start_time = time.time()\n",
    "        features = model.predict(input_data)\n",
    "        end_time = time.time()\n",
    "        timings.append(end_time - start_time)\n",
    "        if i % print_step == 0:\n",
    "            print(\n",
    "                f'Iteration {i}/{nruns}, avg batch time {np.mean(timings) * 1000:.2f} ± {np.std(timings) * 1000:.2f} ms.'\n",
    "            )\n",
    "\n",
    "    print(f'Input shape: {input_data.shape}')\n",
    "    print(f'{prefiks} Average throughput: {input_shape[0] / np.mean(timings):.2f} images/second')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MMdetWrapper:\n",
    "    def __init__(self, model: torch.nn.Module):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "\n",
    "    def predict(self, input_data: np.ndarray) -> np.ndarray:\n",
    "        result = inference_detector(model, input_data[0])\n",
    "        return result\n",
    "\n",
    "\n",
    "class ONNXRuntimeWrapper:\n",
    "    def __init__(self, ort_session: Any):\n",
    "        self.session = ort_session\n",
    "        self.input_name = [input_.name for input_ in ort_session.get_inputs()][0]\n",
    "\n",
    "    def predict(self, input_data: np.ndarray) -> np.ndarray:\n",
    "        return self.session.run(None, {self.input_name: input_data})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.get_device_name(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICES = ['cpu']\n",
    "ONNX_PROVIDERS = ['CPUExecutionProvider']\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    ONNX_PROVIDERS += [\n",
    "        ('CUDAExecutionProvider', {f'device_id': cuda_i,}) for cuda_i in range(torch.cuda.device_count())\n",
    "    ]\n",
    "    DEVICES += [f'cuda:{cuda_i}' for cuda_i in range(torch.cuda.device_count())]\n",
    "else:\n",
    "    DEVICES = ['cuda:0', 'cpu']\n",
    "    ONNX_PROVIDERS = [\n",
    "        'CUDAExecutionProvider',\n",
    "        'CPUExecutionProvider',\n",
    "    ]\n",
    "\n",
    "config_files = ['../src/mmdet_maskrcnn.py', '../src/mmdet_mask2former.py', ]\n",
    "checkpoint_files = ['../models/MaskRCNN-ResNet50.pth', '../models/Mask2Former-ResNet50.pth', ]\n",
    "\n",
    "ONNX_MODEL_NAMES = [\n",
    "    '../models/YOLOv11m-seg.onnx',\n",
    "    '../models/UNet-MobileNetV3-large-075.onnx',\n",
    "    '../models/UNet-ResNet50.onnx',\n",
    "    '../models/FPN-ResNet50.onnx',\n",
    "    '../models/MAnet-ResNet50.onnx',\n",
    "    '../models/MaskRCNN_MFD.onnx',\n",
    "]\n",
    "\n",
    "NRUNS=2000\n",
    "STEP=500\n",
    "BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ONNX_PROVIDERS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "! lspci | grep -i nvidia\n",
    "! lscpu | grep -i Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_i, checkpoint_file in enumerate(checkpoint_files):\n",
    "    for device in DEVICES:\n",
    "        # init a detector cuda: 1159 Mb, 1161\n",
    "        print(f\"{device}: {checkpoint_file}\")\n",
    "        model = init_detector(config_files[model_i], checkpoint_file, device=device)\n",
    "        mmdet_wrapper = MMdetWrapper(model)\n",
    "        benchmark(mmdet_wrapper, (BATCH_SIZE, 3, 480, 480), nruns=NRUNS, print_step=STEP)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "for onnx_model_path in ONNX_MODEL_NAMES:\n",
    "    for provider in ONNX_PROVIDERS:\n",
    "        # init a detector cuda: 1159 Mb, 1161\n",
    "        print(f\"{provider}: {onnx_model_path}\")\n",
    "        \n",
    "        ort_session = ort.InferenceSession(\n",
    "            onnx_model_path,                       \n",
    "            providers=[provider]                      \n",
    "        )\n",
    "        ort_wrapper = ONNXRuntimeWrapper(ort_session)\n",
    "        benchmark(ort_wrapper, (BATCH_SIZE, 3, 480, 480), nruns=NRUNS, print_step=STEP, prefiks=f\"{provider}: {onnx_model_path}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Evaluate full pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_all(\n",
    "    model: Any,\n",
    "    input_data: Any,\n",
    "    nwarmup: int = 50,\n",
    "    nruns: int = 10000,  # 2000\n",
    "    print_step: int = 1000,  # 500\n",
    "):\n",
    "    print(\"Warm up ...\")\n",
    "    for _ in range(nwarmup):\n",
    "        boxes, masks = model.predict_results(input_data)\n",
    "\n",
    "    print(\"Start timing ...\")\n",
    "    timings = []\n",
    "    boxes_num = []\n",
    "    for i in range(1, nruns + 1):\n",
    "        start_time = time.time()\n",
    "        boxes, masks = model.predict_results(input_data)\n",
    "        end_time = time.time()\n",
    "        timings.append(end_time - start_time)\n",
    "        boxes_num.append(len(list(boxes)))\n",
    "        if i % print_step == 0:\n",
    "            print(\n",
    "                f'Iteration {i}/{nruns}, avg batch time {np.mean(timings) * 1000:.2f} ± {np.std(timings) * 1000:.2f} ms.'\n",
    "            )\n",
    "\n",
    "    print(f'Input shape: {input_data.shape}')\n",
    "    print(f'Predicted {np.mean(boxes_num):.2f} ± {np.std(boxes_num):.2f} boxes')\n",
    "    print(f'Average throughput: {BATCH_SIZE / np.mean(timings):.2f} images/second')\n",
    "\n",
    "\n",
    "def nms_pytorch(P: torch.tensor ,thresh_iou: float):\n",
    "    \"\"\"\n",
    "    Apply non-maximum suppression to avoid detecting too many\n",
    "    overlapping bounding boxes for a given object.\n",
    "    Args:\n",
    "        boxes: (tensor) The location preds for the image \n",
    "            along with the class predscores, Shape: [num_boxes,5].\n",
    "        thresh_iou: (float) The overlap thresh for suppressing unnecessary boxes.\n",
    "    Returns:\n",
    "        A list of filtered boxes, Shape: [ , 5]\n",
    "    \"\"\"\n",
    " \n",
    "    # we extract coordinates for every \n",
    "    # prediction box present in P\n",
    "    x1 = P[:, 0]\n",
    "    y1 = P[:, 1]\n",
    "    x2 = P[:, 2]\n",
    "    y2 = P[:, 3]\n",
    " \n",
    "    # we extract the confidence scores as well\n",
    "    scores = P[:, 4]\n",
    " \n",
    "    # calculate area of every block in P\n",
    "    areas = (x2 - x1) * (y2 - y1)\n",
    "     \n",
    "    # sort the prediction boxes in P\n",
    "    # according to their confidence scores\n",
    "    order = scores.argsort()\n",
    " \n",
    "    # initialise an empty list for \n",
    "    # filtered prediction boxes\n",
    "    keep = []\n",
    "    while len(order) > 0:\n",
    "         \n",
    "        # extract the index of the \n",
    "        # prediction with highest score\n",
    "        # we call this prediction S\n",
    "        idx = order[-1]\n",
    " \n",
    "        # push S in filtered predictions list\n",
    "        keep.append(P[idx])\n",
    " \n",
    "        # remove S from P\n",
    "        order = order[:-1]\n",
    " \n",
    "        # sanity check\n",
    "        if len(order) == 0:\n",
    "            break\n",
    "         \n",
    "        # select coordinates of BBoxes according to \n",
    "        # the indices in order\n",
    "        xx1 = torch.index_select(x1,dim = 0, index = order)\n",
    "        xx2 = torch.index_select(x2,dim = 0, index = order)\n",
    "        yy1 = torch.index_select(y1,dim = 0, index = order)\n",
    "        yy2 = torch.index_select(y2,dim = 0, index = order)\n",
    " \n",
    "        # find the coordinates of the intersection boxes\n",
    "        xx1 = torch.max(xx1, x1[idx])\n",
    "        yy1 = torch.max(yy1, y1[idx])\n",
    "        xx2 = torch.min(xx2, x2[idx])\n",
    "        yy2 = torch.min(yy2, y2[idx])\n",
    " \n",
    "        # find height and width of the intersection boxes\n",
    "        w = xx2 - xx1\n",
    "        h = yy2 - yy1\n",
    "         \n",
    "        # take max with 0.0 to avoid negative w and h\n",
    "        # due to non-overlapping boxes\n",
    "        w = torch.clamp(w, min=0.0)\n",
    "        h = torch.clamp(h, min=0.0)\n",
    " \n",
    "        # find the intersection area\n",
    "        inter = w*h\n",
    " \n",
    "        # find the areas of BBoxes according the indices in order\n",
    "        rem_areas = torch.index_select(areas, dim = 0, index = order) \n",
    " \n",
    "        # find the union of every prediction T in P\n",
    "        # with the prediction S\n",
    "        # Note that areas[idx] represents area of S\n",
    "        union = (rem_areas - inter) + areas[idx]\n",
    "         \n",
    "        # find the IoU of every prediction in P with S\n",
    "        IoU = inter / union\n",
    " \n",
    "        # keep the boxes with IoU less than thresh_iou\n",
    "        mask = IoU < thresh_iou\n",
    "        order = order[mask]\n",
    "     \n",
    "    return keep\n",
    "\n",
    "\n",
    "def onnx_preprocessing(\n",
    "    image: np.ndarray,\n",
    "    image_size: tp.Tuple[int, int] = (224, 224),\n",
    ") -> np.ndarray:\n",
    "    # resize\n",
    "    image = cv2.resize(image.copy(), image_size, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    # normalize\n",
    "    mean = np.array((0.485, 0.456, 0.406), dtype=np.float32) * 255.0\n",
    "    std = np.array((0.229, 0.224, 0.225), dtype=np.float32) * 255.0\n",
    "    denominator = np.reciprocal(std, dtype=np.float32)\n",
    "    image = image.astype(np.float32)\n",
    "    image -= mean\n",
    "    image *= denominator\n",
    "\n",
    "    # transpose\n",
    "    image = image.transpose((2, 0, 1))[None]\n",
    "    return image\n",
    "\n",
    "\n",
    "def intersection(box1,box2):\n",
    "    box1_x1,box1_y1,box1_x2,box1_y2 = box1[:4]\n",
    "    box2_x1,box2_y1,box2_x2,box2_y2 = box2[:4]\n",
    "    x1 = max(box1_x1,box2_x1)\n",
    "    y1 = max(box1_y1,box2_y1)\n",
    "    x2 = min(box1_x2,box2_x2)\n",
    "    y2 = min(box1_y2,box2_y2)\n",
    "    return (x2-x1)*(y2-y1) \n",
    "\n",
    "\n",
    "def union(box1,box2):\n",
    "    box1_x1,box1_y1,box1_x2,box1_y2 = box1[:4]\n",
    "    box2_x1,box2_y1,box2_x2,box2_y2 = box2[:4]\n",
    "    box1_area = (box1_x2-box1_x1)*(box1_y2-box1_y1)\n",
    "    box2_area = (box2_x2-box2_x1)*(box2_y2-box2_y1)\n",
    "    return box1_area + box2_area - intersection(box1,box2)\n",
    "\n",
    "\n",
    "def iou(box1,box2):\n",
    "    return intersection(box1,box2)/union(box1,box2)\n",
    "\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MMdetWrapper:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def set_session(self, model: torch.nn.Module):\n",
    "        self.model = model\n",
    "\n",
    "    def predict_results(self, input_data: np.ndarray) -> tuple:\n",
    "        result = inference_detector(model, [input_data])[0]\n",
    "        pred_boxes = result.pred_instances.bboxes.detach().cpu().numpy()\n",
    "        pred_scores = result.pred_instances.scores.detach().cpu().numpy()\n",
    "        pred_masks = result.pred_instances.masks.detach().cpu().numpy()\n",
    "        \n",
    "        pred_boxes = pred_boxes[pred_scores >= 0.7]\n",
    "        pred_masks = pred_masks[pred_scores >= 0.7]\n",
    "        return pred_boxes, pred_masks\n",
    "\n",
    "\n",
    "class ONNXRuntimeWrapperMaskRCNN:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def set_session(self, ort_session: Any):\n",
    "        self.session = ort_session\n",
    "        self.input_name = [input_.name for input_ in ort_session.get_inputs()][0]\n",
    "\n",
    "    def predict_results(self, input_data: np.ndarray) -> tuple:\n",
    "        boxes_scores, labels, masks = self.session.run(None, {self.input_name: input_data})\n",
    "        boxes = boxes_scores[0,:,:4]  # raw bounding boxes\n",
    "        scores = boxes_scores[0,:,4]   # scores\n",
    "        labels = labels[0,:]           # raw labels\n",
    "        masks = np.transpose(masks, [1, 0, 2, 3])\n",
    "        return boxes, masks\n",
    "\n",
    "\n",
    "class ONNXRuntimeWrapperYOLO:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def set_session(self, ort_session: Any):\n",
    "        self.session = ort_session\n",
    "        self.input_name = [input_.name for input_ in ort_session.get_inputs()][0]\n",
    "\n",
    "    def predict_results(self, input_data: np.ndarray) -> tuple:\n",
    "        prediction, mask_info = self.session.run(None, {self.input_name: input_data})\n",
    "        number_of_classes = 1\n",
    "        mask_index = 4 + number_of_classes\n",
    "        prediction = prediction[0].transpose()\n",
    "        pass_boxes_mask = prediction[:, 4:mask_index] >= 0.7\n",
    "        pass_data = []\n",
    "        for xi, x in enumerate(prediction):  # image index, image inference\n",
    "            if pass_boxes_mask[xi][0]:\n",
    "                xc, yc, w, h, prob = x[:5]\n",
    "                x1 = xc - w / 2\n",
    "                y1 = yc - h / 2\n",
    "                x2 = xc + w / 2\n",
    "                y2 = yc + h / 2\n",
    "                masks = x[5:]\n",
    "                pass_data.append(np.array([x1, y1, x2, y2, prob] + list(masks)))\n",
    "    \n",
    "        pass_data_result = []\n",
    "        pass_data.sort(key=lambda x: x[4], reverse=True)\n",
    "        while len(pass_data) > 0:\n",
    "            pass_data_result.append(pass_data[0])\n",
    "            pass_data = [\n",
    "                box for box in pass_data if iou(\n",
    "                    box[:4], pass_data[0][:4]\n",
    "                ) < 0.7\n",
    "            ]\n",
    "    \n",
    "        pass_results = np.array(pass_data_result)\n",
    "        masks = pass_results[:, 5:]\n",
    "        boxes = pass_results[:, :5]\n",
    "    \n",
    "        mask_len, mask_h, mask_w = mask_info.shape[1:]\n",
    "        output1 = mask_info[0].reshape(\n",
    "            mask_len, mask_h * mask_w\n",
    "        )\n",
    "        masks = masks @ output1  # (n, 32) (32, 25600)\n",
    "        return boxes, masks\n",
    "\n",
    "\n",
    "class ONNXRuntimeWrapperSemantic:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def set_session(self, ort_session: Any):\n",
    "        self.session = ort_session\n",
    "        self.input_name = [input_.name for input_ in ort_session.get_inputs()][0]\n",
    "\n",
    "    def predict_results(self, input_data: np.ndarray) -> tuple:\n",
    "        ort_outputs = self.session.run(None, {self.input_name: input_data})[0]\n",
    "        pr_mask = ort_outputs.squeeze().round()\n",
    "        pr_mask = np.exp(-np.logaddexp(0, -pr_mask))  # sigmoid\n",
    "        pr_mask[pr_mask >= 0.7] = 255\n",
    "        pr_mask[pr_mask < 0.7] = 0\n",
    "        pr_mask = pr_mask.astype(np.uint8)\n",
    "    \n",
    "        cnts, hierarchy = cv2.findContours(\n",
    "                pr_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE\n",
    "            )\n",
    "        boxes = []\n",
    "        for cnt in cnts:\n",
    "            x1,y1,w,h = cv2.boundingRect(cnt)\n",
    "            boxes.append([int(x1), int(y1), int(x1+w), int(y1+h)])\n",
    "        return boxes, pr_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = cv2.imread('../IoU_test/images/50-NH4NO3_prill.jpg')\n",
    "granules_number = 0\n",
    "test_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "onnx_input = onnx_preprocessing(\n",
    "    test_image,\n",
    "    image_size=(480, 480)\n",
    ")\n",
    "onnx_input = np.concatenate([onnx_input] * BATCH_SIZE)\n",
    "\n",
    "MODELS = {\n",
    "    '../models/UNet-MobileNetV3-large-075.onnx': {\n",
    "        'input': onnx_input,\n",
    "        'wrapper': ONNXRuntimeWrapperSemantic(),\n",
    "        'devices': ONNX_PROVIDERS\n",
    "    },\n",
    "    '../models/UNet-ResNet50.onnx': {\n",
    "        'input': onnx_input,\n",
    "        'wrapper': ONNXRuntimeWrapperSemantic(),\n",
    "        'devices': ONNX_PROVIDERS\n",
    "    },\n",
    "    '../models/FPN-ResNet50.onnx': {\n",
    "        'input': onnx_input,\n",
    "        'wrapper': ONNXRuntimeWrapperSemantic(),\n",
    "        'devices': ONNX_PROVIDERS\n",
    "    },\n",
    "    '../models/MAnet-ResNet50.onnx': {\n",
    "        'input': onnx_input,\n",
    "        'wrapper': ONNXRuntimeWrapperSemantic(),\n",
    "        'devices': ONNX_PROVIDERS\n",
    "    },\n",
    "    '../models/MaskRCNN-ResNet50.onnx': {\n",
    "        'input': onnx_input,\n",
    "        'wrapper': ONNXRuntimeWrapperMaskRCNN(),\n",
    "        'devices': ONNX_PROVIDERS\n",
    "    },\n",
    "    '../models/YOLOv11m-seg.onnx': {\n",
    "        'input': onnx_input,\n",
    "        'wrapper': ONNXRuntimeWrapperYOLO(),\n",
    "        'devices': ONNX_PROVIDERS\n",
    "    },\n",
    "    '../models/Mask2Former-ResNet50.pth': {\n",
    "        'input': test_image,\n",
    "        'wrapper': MMdetWrapper(),\n",
    "        'devices': DEVICES\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_path in MODELS:\n",
    "    print(model_path)\n",
    "    for device in MODELS[model_path]['devices']:\n",
    "        print(f'\\t {device}:')\n",
    "        if 'Mask2Former' in model_path:\n",
    "            print(f'\\t not ONNX')\n",
    "            MODELS[model_path]['wrapper'].set_session(\n",
    "                init_detector('../src/mmdet_mask2former.py', '../models/Mask2Former-ResNet50.pth', device=device)\n",
    "            )\n",
    "        else:\n",
    "            ort_session = ort.InferenceSession(\n",
    "                model_path,\n",
    "                providers=[device]\n",
    "            )\n",
    "            MODELS[model_path]['wrapper'].set_session(ort_session)\n",
    "        benchmark_all(\n",
    "            MODELS[model_path]['wrapper'], \n",
    "            MODELS[model_path]['input'], \n",
    "            nruns=NRUNS,\n",
    "            print_step=STEP\n",
    "        )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Inference segmentation with classical CV\n",
    "\n",
    "Load model from [segmentation models](https://github.com/qubvel-org/segmentation_models.pytorch) and process some test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import typing as tp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import onnxruntime as ort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIR = '../test_images'\n",
    "DEVICE = 'cpu'\n",
    "NN_THRESHOLD = 0.7\n",
    "BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onnx_preprocessing(\n",
    "    image: np.ndarray,\n",
    "    image_size: tp.Tuple[int, int] = (224, 224),\n",
    ") -> np.ndarray:\n",
    "    # resize\n",
    "    image = cv2.resize(image.copy(), image_size, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    # normalize\n",
    "    mean = np.array((0.485, 0.456, 0.406), dtype=np.float32) * 255.0\n",
    "    std = np.array((0.229, 0.224, 0.225), dtype=np.float32) * 255.0\n",
    "    denominator = np.reciprocal(std, dtype=np.float32)\n",
    "    image = image.astype(np.float32)\n",
    "    image -= mean\n",
    "    image *= denominator\n",
    "\n",
    "    # transpose\n",
    "    image = image.transpose((2, 0, 1))[None]\n",
    "    return image\n",
    "\n",
    "\n",
    "def binary_mask_iou(\n",
    "        mask1: np.array,\n",
    "        mask2: np.array,\n",
    "        label_value: int = 1,\n",
    ") -> float:\n",
    "    mask1_area = np.count_nonzero(mask1 == label_value)\n",
    "    mask2_area = np.count_nonzero(mask2 == label_value)\n",
    "    intersection = np.count_nonzero(\n",
    "        np.logical_and(mask1==label_value,  mask2==label_value)\n",
    "    )\n",
    "    return intersection / (mask1_area + mask2_area-intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Process annotations data\n",
    "d_path_annot = '../IoU_test/annotations/balanced_test.json'\n",
    "d_path_images = '../IoU_test/images'\n",
    "\n",
    "processed_data = {\n",
    "    'Id': [],\n",
    "    'image_path': [],\n",
    "    'semantic_masks': [],\n",
    "    'granules_number': []\n",
    "}\n",
    "\n",
    "with open(d_path_annot, 'r', encoding=\"utf-8\") as json_file:\n",
    "    json_data_dir = json.load(json_file)\n",
    "    # Process image data\n",
    "    for image_inf in tqdm(json_data_dir['images'], desc=\"Process images: \"):\n",
    "        real_img_id = image_inf['id']\n",
    "        for k in processed_data:\n",
    "            processed_data[k].append([])\n",
    "        processed_data['Id'][-1] = real_img_id\n",
    "        img_name = image_inf['file_name'].split('/')[-1]\n",
    "        img_path = os.path.join(\n",
    "            d_path_images, img_name\n",
    "        )\n",
    "        processed_data['image_path'][-1] = str(img_path)\n",
    "        SIZE = (image_inf['height'], image_inf['width'], 3)\n",
    "        processed_data['semantic_masks'][-1] = np.zeros(SIZE[:2], dtype=np.uint8)\n",
    "        processed_data['granules_number'][-1] = 0\n",
    "\n",
    "with open(d_path_annot, 'r') as json_file:\n",
    "    json_data_dir = json.load(json_file)\n",
    "    image_id_old = ''\n",
    "    skipped_counter = 1\n",
    "    morph_kernel = cv2.getStructuringElement(\n",
    "        cv2.MORPH_ELLIPSE, (3, 3)\n",
    "    )\n",
    "\n",
    "    for annotation_data in tqdm(\n",
    "        json_data_dir['annotations'], desc=\"Process annotations: \"\n",
    "    ):\n",
    "        # Data may be numerated to image of have through numeration\n",
    "        process_image_id = annotation_data['image_id']\n",
    "\n",
    "        image_data_indx = processed_data['Id'].index(process_image_id)\n",
    "        label = annotation_data['category_id']\n",
    "        # Process each granule\n",
    "        for point_i, point in enumerate(annotation_data['segmentation']):\n",
    "            if isinstance(point, list):\n",
    "                point_xy = [\n",
    "                    [point[j], point[j + 1]] for j in\n",
    "                    range(0, len(point), 2)\n",
    "                ]\n",
    "                cnt = np.array(point_xy).reshape((-1, 1, 2)).astype(\n",
    "                    np.int32\n",
    "                )\n",
    "                if len(cnt) < 3:  # bad contour\n",
    "                    print('Cnt is bad')\n",
    "                    continue\n",
    "\n",
    "                single_mask = np.zeros((480, 480), dtype=np.uint8)\n",
    "                _ = cv2.drawContours(\n",
    "                    single_mask,\n",
    "                    [cnt], -1, label, cv2.FILLED\n",
    "                )\n",
    "                processed_data['semantic_masks'][image_data_indx][single_mask != 0] = label\n",
    "                x, y, w, h = annotation_data[\"bbox\"]\n",
    "                processed_data['granules_number'][image_data_indx] += 1\n",
    "            else:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test valid\n",
    "import random\n",
    "random_i = random.randint(0, len(processed_data['Id'])-1)\n",
    "\n",
    "random_mask_all = processed_data['semantic_masks'][random_i]\n",
    "img = random_mask_all.copy()\n",
    "img[img > 0] = 255\n",
    "\n",
    "print((\n",
    "    f\"Image: {processed_data['image_path'][random_i]},\\n\"\n",
    "    f\" total granules: {processed_data['granules_number'][random_i]}.\\n\"\n",
    "))\n",
    "\n",
    "\n",
    "test_image = cv2.imread(processed_data['image_path'][random_i])\n",
    "test_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 20]\n",
    "f, axarr = plt.subplots(2,1)\n",
    "\n",
    "axarr[0].imshow(test_image, cmap='gray', vmin=0, vmax=255)\n",
    "axarr[1].imshow(img, cmap='gray', vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Unet\n",
    " \n",
    "[Unet](https://arxiv.org/abs/1505.04597) + [timm-mobilenetv3_small_minimal_100](https://smp.readthedocs.io/en/latest/encoders.html#mobilenet) + [`cv2.findContours`](https://docs.opencv.org/4.x/d3/dc0/group__imgproc__shape.html#gadf1ad6a0b82947fa1fe3c3d497f260e0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "providers = [\n",
    "    'CUDAExecutionProvider',\n",
    "    'CPUExecutionProvider',\n",
    "]\n",
    "\n",
    "ort_session = ort.InferenceSession(\n",
    "    '../models/UNet-MobileNetV3-large-075-200.onnx',\n",
    "    providers=providers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple contours find\n",
    "for image_path in list(os.walk(IMAGE_DIR + '/preprocess/'))[0][2]:\n",
    "    if 'png' not in image_path:\n",
    "        continue\n",
    "    print('process: ', image_path)\n",
    "    test_image = cv2.imread(IMAGE_DIR + '/preprocess/' + image_path)\n",
    "    test_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    onnx_input = onnx_preprocessing(test_image, image_size=(480, 480))\n",
    "    onnx_input = np.concatenate([onnx_input] * BATCH_SIZE)\n",
    "    ort_inputs = {ort_session.get_inputs()[0].name: onnx_input}\n",
    "    ort_outputs = ort_session.run(None, ort_inputs)[0]\n",
    "\n",
    "    pr_mask = ort_outputs.squeeze().round()\n",
    "    pr_mask = np.exp(-np.logaddexp(0, -pr_mask))  # sigmoid\n",
    "    pr_mask[pr_mask >= NN_THRESHOLD] = 255\n",
    "    pr_mask[pr_mask < NN_THRESHOLD] = 0\n",
    "    pr_mask = pr_mask.astype(np.uint8)\n",
    "\n",
    "    cnts, hierarchy = cv2.findContours(\n",
    "            pr_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE\n",
    "        )\n",
    "    for cnt in cnts:\n",
    "        x1,y1,w,h = cv2.boundingRect(cnt)\n",
    "        test_image = cv2.rectangle(\n",
    "            test_image,\n",
    "            (int(x1), int(y1)), (int(x1+w), int(y1+h)),\n",
    "            (255,0,0),\n",
    "            2\n",
    "        )\n",
    "\n",
    "    green_masks = np.zeros(test_image.shape, np.uint8)\n",
    "    green_masks[:,:,0][pr_mask > 0] = 61\n",
    "    green_masks[:,:,1][pr_mask > 0] = 142\n",
    "    green_masks[:,:,2][pr_mask > 0] = 48\n",
    "\n",
    "    test_image = cv2.addWeighted(test_image, 0.6, green_masks, 0.4, 0)\n",
    "    _ = cv2.imwrite(IMAGE_DIR + f'/final/Unet-mobilenet_{int(NN_THRESHOLD*10)}_' + image_path, cv2.cvtColor(test_image, cv2.COLOR_RGB2BGR))\n",
    "    time.sleep(1)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    _ = ax.imshow(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_iou = []\n",
    "total_granules_det = []\n",
    "\n",
    "for image_i, image_path in enumerate(tqdm(processed_data['image_path'])):\n",
    "    test_image = cv2.imread(image_path)\n",
    "    test_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)\n",
    "    gt_mask = processed_data['semantic_masks'][image_i]\n",
    "\n",
    "    onnx_input = onnx_preprocessing(test_image, image_size=(480, 480))\n",
    "    onnx_input = np.concatenate([onnx_input] * BATCH_SIZE)\n",
    "    ort_inputs = {ort_session.get_inputs()[0].name: onnx_input}\n",
    "    ort_outputs = ort_session.run(None, ort_inputs)[0]\n",
    "\n",
    "    pr_mask = ort_outputs.squeeze().round()\n",
    "    pr_mask = np.exp(-np.logaddexp(0, -pr_mask))  # sigmoid\n",
    "    pr_mask[pr_mask >= NN_THRESHOLD] = 1\n",
    "    pr_mask[pr_mask < NN_THRESHOLD] = 0\n",
    "    pr_mask = pr_mask.astype(np.uint8)\n",
    "\n",
    "    cnts, hierarchy = cv2.findContours(\n",
    "            pr_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE\n",
    "        )\n",
    "    total_granules_det.append(len(cnts))\n",
    "    total_iou.append(binary_mask_iou(gt_mask, pr_mask))\n",
    "\n",
    "granules_deviation = np.abs((np.array(total_granules_det) - np.array(processed_data['granules_number']))) / np.array(processed_data['granules_number']) * 100\n",
    "granules_detected = (np.array(total_granules_det) / np.array(processed_data['granules_number'])) * 100\n",
    "\n",
    "\n",
    "print(f\"Median and Average IoU for all dataset = {np.median(total_iou)} VS {np.average(total_iou)}, disp = {np.std(total_iou)}\")\n",
    "print(f\"Median and Average granules devianion for all dataset = {np.median(granules_deviation)} VS {np.average(granules_deviation)}, disp = {np.std(granules_deviation)}\")\n",
    "print(f\"Median and Average granules detected for all dataset = {np.median(granules_detected)} VS {np.average(granules_deviation)}, disp = {np.std(granules_detected)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Unet\n",
    "\n",
    "[Unet](https://arxiv.org/abs/1505.04597) + ResNet50 + [`cv2.findContours`](https://docs.opencv.org/4.x/d3/dc0/group__imgproc__shape.html#gadf1ad6a0b82947fa1fe3c3d497f260e0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "providers = [\n",
    "    'CUDAExecutionProvider',\n",
    "    'CPUExecutionProvider',\n",
    "]\n",
    "\n",
    "ort_session = ort.InferenceSession(\n",
    "    '../models/UNet-ResNet50.onnx',\n",
    "    providers=providers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple contours find\n",
    "for image_path in list(os.walk(IMAGE_DIR + '/preprocess/'))[0][2]:\n",
    "    if 'png' not in image_path:\n",
    "        continue\n",
    "    print('process: ', image_path)\n",
    "    test_image = cv2.imread(IMAGE_DIR + '/preprocess/' + image_path)\n",
    "    test_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    onnx_input = onnx_preprocessing(test_image, image_size=(480, 480))\n",
    "    onnx_input = np.concatenate([onnx_input] * BATCH_SIZE)\n",
    "    ort_inputs = {ort_session.get_inputs()[0].name: onnx_input}\n",
    "    ort_outputs = ort_session.run(None, ort_inputs)[0]\n",
    "\n",
    "    pr_mask = ort_outputs.squeeze().round()\n",
    "    pr_mask = np.exp(-np.logaddexp(0, -pr_mask))  # sigmoid\n",
    "    pr_mask[pr_mask >= NN_THRESHOLD] = 255\n",
    "    pr_mask[pr_mask < NN_THRESHOLD] = 0\n",
    "    pr_mask = pr_mask.astype(np.uint8)\n",
    "\n",
    "    cnts, hierarchy = cv2.findContours(\n",
    "            pr_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE\n",
    "        )\n",
    "    for cnt in cnts:\n",
    "        x1,y1,w,h = cv2.boundingRect(cnt)\n",
    "        test_image = cv2.rectangle(\n",
    "            test_image,\n",
    "            (int(x1), int(y1)), (int(x1+w), int(y1+h)),\n",
    "            (255,0,0),\n",
    "            2\n",
    "        )\n",
    "\n",
    "    green_masks = np.zeros(test_image.shape, np.uint8)\n",
    "    green_masks[:,:,0][pr_mask > 0] = 61\n",
    "    green_masks[:,:,1][pr_mask > 0] = 142\n",
    "    green_masks[:,:,2][pr_mask > 0] = 48\n",
    "\n",
    "    test_image = cv2.addWeighted(test_image, 0.6, green_masks, 0.4, 0)\n",
    "    _ = cv2.imwrite(IMAGE_DIR + f'/final/Unet-ResNet50_{int(NN_THRESHOLD*10)}_' + image_path, cv2.cvtColor(test_image, cv2.COLOR_RGB2BGR))\n",
    "    time.sleep(1)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    _ = ax.imshow(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_iou = []\n",
    "total_granules_det = []\n",
    "\n",
    "for image_i, image_path in enumerate(tqdm(processed_data['image_path'])):\n",
    "    test_image = cv2.imread(image_path)\n",
    "    test_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)\n",
    "    gt_mask = processed_data['semantic_masks'][image_i]\n",
    "\n",
    "    onnx_input = onnx_preprocessing(test_image, image_size=(480, 480))\n",
    "    onnx_input = np.concatenate([onnx_input] * BATCH_SIZE)\n",
    "    ort_inputs = {ort_session.get_inputs()[0].name: onnx_input}\n",
    "    ort_outputs = ort_session.run(None, ort_inputs)[0]\n",
    "\n",
    "    pr_mask = ort_outputs.squeeze().round()\n",
    "    pr_mask = np.exp(-np.logaddexp(0, -pr_mask))  # sigmoid\n",
    "    pr_mask[pr_mask >= NN_THRESHOLD] = 1\n",
    "    pr_mask[pr_mask < NN_THRESHOLD] = 0\n",
    "    pr_mask = pr_mask.astype(np.uint8)\n",
    "\n",
    "    cnts, hierarchy = cv2.findContours(\n",
    "            pr_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE\n",
    "        )\n",
    "    total_granules_det.append(len(cnts))\n",
    "    total_iou.append(binary_mask_iou(gt_mask, pr_mask))\n",
    "\n",
    "granules_deviation = np.abs((np.array(total_granules_det) - np.array(processed_data['granules_number']))) / np.array(processed_data['granules_number']) * 100\n",
    "granules_detected = (np.array(total_granules_det) / np.array(processed_data['granules_number'])) * 100\n",
    "\n",
    "\n",
    "print(f\"Median and Average IoU for all dataset = {np.median(total_iou)} VS {np.average(total_iou)}, disp = {np.std(total_iou)}\")\n",
    "print(f\"Median and Average granules devianion for all dataset = {np.median(granules_deviation)} VS {np.average(granules_deviation)}, disp = {np.std(granules_deviation)}\")\n",
    "print(f\"Median and Average granules detected for all dataset = {np.median(granules_detected)} VS {np.average(granules_detected)}, disp = {np.std(granules_detected)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## FPN\n",
    "\n",
    "[FPN](http://presentations.cocodataset.org/COCO17-Stuff-FAIR.pdf) + ResNet50 + [`cv2.findContours`](https://docs.opencv.org/4.x/d3/dc0/group__imgproc__shape.html#gadf1ad6a0b82947fa1fe3c3d497f260e0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "providers = [\n",
    "    'CUDAExecutionProvider',\n",
    "    'CPUExecutionProvider',\n",
    "]\n",
    "\n",
    "ort_session = ort.InferenceSession(\n",
    "    '../models/FPN-ResNet50.onnx',\n",
    "    providers=providers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple contours find\n",
    "for image_path in list(os.walk(IMAGE_DIR + '/preprocess/'))[0][2]:\n",
    "    test_image = cv2.imread(IMAGE_DIR + '/preprocess/' + image_path)\n",
    "    test_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    onnx_input = onnx_preprocessing(test_image, image_size=(480, 480))\n",
    "    onnx_input = np.concatenate([onnx_input] * BATCH_SIZE)\n",
    "    ort_inputs = {ort_session.get_inputs()[0].name: onnx_input}\n",
    "    ort_outputs = ort_session.run(None, ort_inputs)[0]\n",
    "\n",
    "    pr_mask = ort_outputs.squeeze().round()\n",
    "    # pr_mask = (pr_mask.squeeze().cpu().detach().numpy().round())\n",
    "    pr_mask = np.exp(-np.logaddexp(0, -pr_mask))  # sigmoid\n",
    "    pr_mask[pr_mask >= NN_THRESHOLD] = 255\n",
    "    pr_mask[pr_mask < NN_THRESHOLD] = 0\n",
    "    pr_mask = pr_mask.astype(np.uint8)\n",
    "\n",
    "    cnts, hierarchy = cv2.findContours(\n",
    "            pr_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE\n",
    "        )\n",
    "    for cnt in cnts:\n",
    "        x1,y1,w,h = cv2.boundingRect(cnt)\n",
    "        test_image = cv2.rectangle(\n",
    "            test_image,\n",
    "            (int(x1), int(y1)), (int(x1+w), int(y1+h)),\n",
    "            (255,0,0),\n",
    "            2\n",
    "        )\n",
    "\n",
    "    green_masks = np.zeros(test_image.shape, np.uint8)\n",
    "    green_masks[:,:,0][pr_mask > 0] = 61\n",
    "    green_masks[:,:,1][pr_mask > 0] = 142\n",
    "    green_masks[:,:,2][pr_mask > 0] = 48\n",
    "\n",
    "    test_image = cv2.addWeighted(test_image, 0.6, green_masks, 0.4, 0)\n",
    "    _ = cv2.imwrite(IMAGE_DIR + f'/final/FPN_{int(NN_THRESHOLD*10)}_' + image_path, cv2.cvtColor(test_image, cv2.COLOR_RGB2BGR))\n",
    "    time.sleep(1)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    _ = ax.imshow(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_iou = []\n",
    "total_granules_det = []\n",
    "\n",
    "for image_i, image_path in enumerate(tqdm(processed_data['image_path'])):\n",
    "    test_image = cv2.imread(image_path)\n",
    "    test_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)\n",
    "    gt_mask = processed_data['semantic_masks'][image_i]\n",
    "\n",
    "    onnx_input = onnx_preprocessing(test_image, image_size=(480, 480))\n",
    "    onnx_input = np.concatenate([onnx_input] * BATCH_SIZE)\n",
    "    ort_inputs = {ort_session.get_inputs()[0].name: onnx_input}\n",
    "    ort_outputs = ort_session.run(None, ort_inputs)[0]\n",
    "\n",
    "    pr_mask = ort_outputs.squeeze().round()\n",
    "    pr_mask = np.exp(-np.logaddexp(0, -pr_mask))  # sigmoid\n",
    "    pr_mask[pr_mask >= NN_THRESHOLD] = 1\n",
    "    pr_mask[pr_mask < NN_THRESHOLD] = 0\n",
    "    pr_mask = pr_mask.astype(np.uint8)\n",
    "\n",
    "    cnts, hierarchy = cv2.findContours(\n",
    "            pr_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE\n",
    "        )\n",
    "    total_granules_det.append(len(cnts))\n",
    "    total_iou.append(binary_mask_iou(gt_mask, pr_mask))\n",
    "\n",
    "granules_deviation = np.abs((np.array(total_granules_det) - np.array(processed_data['granules_number']))) / np.array(processed_data['granules_number']) * 100\n",
    "granules_detected = (np.array(total_granules_det) / np.array(processed_data['granules_number'])) * 100\n",
    "\n",
    "\n",
    "print(f\"Median and Average IoU for all dataset = {np.median(total_iou)} VS {np.average(total_iou)}, disp = {np.std(total_iou)}\")\n",
    "print(f\"Median and Average granules devianion for all dataset = {np.median(granules_deviation)} VS {np.average(granules_deviation)}, disp = {np.std(granules_deviation)}\")\n",
    "print(f\"Median and Average granules detected for all dataset = {np.median(granules_detected)} VS {np.average(granules_detected)}, disp = {np.std(granules_detected)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## MAnet\n",
    "\n",
    "[MAnet](https://ieeexplore.ieee.org/abstract/document/9201310) + [timm-mobilenetv3_large_100](https://smp.readthedocs.io/en/latest/encoders.html#mobilenet) + [`cv2.findContours`](https://docs.opencv.org/4.x/d3/dc0/group__imgproc__shape.html#gadf1ad6a0b82947fa1fe3c3d497f260e0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "providers = [\n",
    "    'CUDAExecutionProvider',\n",
    "    'CPUExecutionProvider',\n",
    "]\n",
    "\n",
    "ort_session = ort.InferenceSession(\n",
    "    '../models/MAnet-ResNet50.onnx',\n",
    "    providers=providers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple contours find\n",
    "for image_path in list(os.walk(IMAGE_DIR + '/preprocess/'))[0][2]:\n",
    "    test_image = cv2.imread(IMAGE_DIR + '/preprocess/' + image_path)\n",
    "    test_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    onnx_input = onnx_preprocessing(test_image, image_size=(480, 480))\n",
    "    onnx_input = np.concatenate([onnx_input] * BATCH_SIZE)\n",
    "    ort_inputs = {ort_session.get_inputs()[0].name: onnx_input}\n",
    "    ort_outputs = ort_session.run(None, ort_inputs)[0]\n",
    "\n",
    "    pr_mask = ort_outputs.squeeze().round()\n",
    "    pr_mask = np.exp(-np.logaddexp(0, -pr_mask))  # sigmoid\n",
    "    pr_mask[pr_mask >= NN_THRESHOLD] = 255\n",
    "    pr_mask[pr_mask < NN_THRESHOLD] = 0\n",
    "    pr_mask = pr_mask.astype(np.uint8)\n",
    "\n",
    "    cnts, hierarchy = cv2.findContours(\n",
    "            pr_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE\n",
    "        )\n",
    "    for cnt in cnts:\n",
    "        x1,y1,w,h = cv2.boundingRect(cnt)\n",
    "        test_image = cv2.rectangle(\n",
    "            test_image,\n",
    "            (int(x1), int(y1)), (int(x1+w), int(y1+h)),\n",
    "            (255,0,0),\n",
    "            2\n",
    "        )\n",
    "\n",
    "    green_masks = np.zeros(test_image.shape, np.uint8)\n",
    "    green_masks[:,:,0][pr_mask > 0] = 61\n",
    "    green_masks[:,:,1][pr_mask > 0] = 142\n",
    "    green_masks[:,:,2][pr_mask > 0] = 48\n",
    "\n",
    "    test_image = cv2.addWeighted(test_image, 0.6, green_masks, 0.4, 0)\n",
    "    _ = cv2.imwrite(IMAGE_DIR + f'/final/MAnet_{int(NN_THRESHOLD*10)}_' + image_path, cv2.cvtColor(test_image, cv2.COLOR_RGB2BGR))\n",
    "    time.sleep(1)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    _ = ax.imshow(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_iou = []\n",
    "total_granules_det = []\n",
    "\n",
    "for image_i, image_path in enumerate(tqdm(processed_data['image_path'])):\n",
    "    test_image = cv2.imread(image_path)\n",
    "    test_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)\n",
    "    gt_mask = processed_data['semantic_masks'][image_i]\n",
    "\n",
    "    onnx_input = onnx_preprocessing(test_image, image_size=(480, 480))\n",
    "    onnx_input = np.concatenate([onnx_input] * BATCH_SIZE)\n",
    "    ort_inputs = {ort_session.get_inputs()[0].name: onnx_input}\n",
    "    ort_outputs = ort_session.run(None, ort_inputs)[0]\n",
    "\n",
    "    pr_mask = ort_outputs.squeeze().round()\n",
    "    pr_mask = np.exp(-np.logaddexp(0, -pr_mask))  # sigmoid\n",
    "    pr_mask[pr_mask >= NN_THRESHOLD] = 1\n",
    "    pr_mask[pr_mask < NN_THRESHOLD] = 0\n",
    "    pr_mask = pr_mask.astype(np.uint8)\n",
    "\n",
    "    cnts, hierarchy = cv2.findContours(\n",
    "            pr_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE\n",
    "        )\n",
    "    total_granules_det.append(len(cnts))\n",
    "    total_iou.append(binary_mask_iou(gt_mask, pr_mask))\n",
    "\n",
    "granules_deviation = np.abs((np.array(total_granules_det) - np.array(processed_data['granules_number']))) / np.array(processed_data['granules_number']) * 100\n",
    "granules_detected = (np.array(total_granules_det) / np.array(processed_data['granules_number'])) * 100\n",
    "\n",
    "\n",
    "print(f\"Median and Average IoU for all dataset = {np.median(total_iou)} VS {np.average(total_iou)}, disp = {np.std(total_iou)}\")\n",
    "print(f\"Median and Average granules devianion for all dataset = {np.median(granules_deviation)} VS {np.average(granules_deviation)}, disp = {np.std(granules_deviation)}\")\n",
    "print(f\"Median and Average granules detected for all dataset = {np.median(granules_detected)} VS {np.average(granules_detected)}, disp = {np.std(granules_detected)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Inference Mask RCNN\n",
    "\n",
    "Load model from [mmdetection framework](https://github.com/open-mmlab/mmdetection) and process some test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import onnxruntime as ort\n",
    "import cv2\n",
    "import typing as tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIR = '../test_images'\n",
    "NN_THRESHOLD = 0.7\n",
    "BATCH_SIZE=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onnx_preprocessing(\n",
    "    image: np.ndarray,\n",
    "    image_size: tp.Tuple[int, int] = (224, 224),\n",
    ") -> np.ndarray:\n",
    "    # resize\n",
    "    image = cv2.resize(image.copy(), image_size, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    # normalize\n",
    "    mean = np.array((0.485, 0.456, 0.406), dtype=np.float32) * 255.0\n",
    "    std = np.array((0.229, 0.224, 0.225), dtype=np.float32) * 255.0\n",
    "    denominator = np.reciprocal(std, dtype=np.float32)\n",
    "    image = image.astype(np.float32)\n",
    "    image -= mean\n",
    "    image *= denominator\n",
    "\n",
    "    # transpose\n",
    "    image = image.transpose((2, 0, 1))[None]\n",
    "    return image\n",
    "\n",
    "\n",
    "def binary_mask_iou(\n",
    "        mask1: np.array,\n",
    "        mask2: np.array,\n",
    "        label_value: int = 1,\n",
    ") -> float:\n",
    "    mask1_area = np.count_nonzero(mask1 == label_value)\n",
    "    mask2_area = np.count_nonzero(mask2 == label_value)\n",
    "    intersection = np.count_nonzero(\n",
    "        np.logical_and(mask1==label_value,  mask2==label_value)\n",
    "    )\n",
    "    return intersection / (mask1_area + mask2_area-intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Process annotations data\n",
    "d_path_annot = '../IoU_test/annotations/balanced_test.json'\n",
    "d_path_images = '../IoU_test/images'\n",
    "\n",
    "processed_data = {\n",
    "    'Id': [],\n",
    "    'image_path': [],\n",
    "    'semantic_masks': [],\n",
    "    'granules_number': []\n",
    "}\n",
    "\n",
    "with open(d_path_annot, 'r', encoding=\"utf-8\") as json_file:\n",
    "    json_data_dir = json.load(json_file)\n",
    "    # Process image data\n",
    "    for image_inf in tqdm(json_data_dir['images'], desc=\"Process images: \"):\n",
    "        real_img_id = image_inf['id']\n",
    "        for k in processed_data:\n",
    "            processed_data[k].append([])\n",
    "        processed_data['Id'][-1] = real_img_id\n",
    "        img_name = image_inf['file_name'].split('/')[-1]\n",
    "        img_path = os.path.join(\n",
    "            d_path_images, img_name\n",
    "        )\n",
    "        processed_data['image_path'][-1] = str(img_path)\n",
    "        SIZE = (image_inf['height'], image_inf['width'], 3)\n",
    "        processed_data['semantic_masks'][-1] = np.zeros(SIZE[:2], dtype=np.uint8)\n",
    "        processed_data['granules_number'][-1] = 0\n",
    "\n",
    "with open(d_path_annot, 'r') as json_file:\n",
    "    json_data_dir = json.load(json_file)\n",
    "    image_id_old = ''\n",
    "    skipped_counter = 1\n",
    "    morph_kernel = cv2.getStructuringElement(\n",
    "        cv2.MORPH_ELLIPSE, (3, 3)\n",
    "    )\n",
    "\n",
    "    for annotation_data in tqdm(\n",
    "        json_data_dir['annotations'], desc=\"Process annotations: \"\n",
    "    ):\n",
    "        # Data may be numerated to image of have through numeration\n",
    "        process_image_id = annotation_data['image_id']\n",
    "\n",
    "        image_data_indx = processed_data['Id'].index(process_image_id)\n",
    "        label = annotation_data['category_id']\n",
    "        # Process each granule\n",
    "        for point_i, point in enumerate(annotation_data['segmentation']):\n",
    "            if isinstance(point, list):\n",
    "                point_xy = [\n",
    "                    [point[j], point[j + 1]] for j in\n",
    "                    range(0, len(point), 2)\n",
    "                ]\n",
    "                cnt = np.array(point_xy).reshape((-1, 1, 2)).astype(\n",
    "                    np.int32\n",
    "                )\n",
    "                if len(cnt) < 3:  # bad contour\n",
    "                    print('Cnt is bad')\n",
    "                    continue\n",
    "\n",
    "                single_mask = np.zeros((480, 480), dtype=np.uint8)\n",
    "                _ = cv2.drawContours(\n",
    "                    single_mask,\n",
    "                    [cnt], -1, label, cv2.FILLED\n",
    "                )\n",
    "                processed_data['semantic_masks'][image_data_indx][single_mask != 0] = label\n",
    "                x, y, w, h = annotation_data[\"bbox\"]\n",
    "                processed_data['granules_number'][image_data_indx] += 1\n",
    "            else:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "providers = [\n",
    "    'CUDAExecutionProvider',\n",
    "    'CPUExecutionProvider',\n",
    "]\n",
    "\n",
    "ort_session = ort.InferenceSession(\n",
    "    '../models/MaskRCNN-ResNet50.onnx',\n",
    "    providers=providers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_path in list(os.walk(IMAGE_DIR + '/preprocess/'))[0][2]:\n",
    "    test_image = cv2.imread(IMAGE_DIR + '/preprocess/' + image_path)\n",
    "    test_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    onnx_input = onnx_preprocessing(test_image, image_size=(480, 480))\n",
    "    onnx_input = np.concatenate([onnx_input] * BATCH_SIZE)\n",
    "    ort_inputs = {ort_session.get_inputs()[0].name: onnx_input}\n",
    "    boxes_scores, labels, masks = ort_session.run(None, ort_inputs)\n",
    "    \n",
    "    bboxes = boxes_scores[0,:,:4] # raw bounding boxes\n",
    "    scores = boxes_scores[0,:,4]   # scores\n",
    "    labels = labels[0,:]           # raw labels\n",
    "    masks = np.transpose(masks, [1, 0, 2, 3])\n",
    "    \n",
    "    green_masks = np.zeros(test_image.shape, dtype=np.uint8)\n",
    "    for bbox_i, bbox in enumerate(bboxes):\n",
    "        if scores[bbox_i] >= NN_THRESHOLD:\n",
    "            _ = cv2.rectangle(\n",
    "                    test_image, \n",
    "                    (int(bbox[0]), int(bbox[1])),\n",
    "                    (int(bbox[2]), int(bbox[3])),\n",
    "                    (255,0,0),\n",
    "                    2\n",
    "                )\n",
    "            bbox = [int(b) for b in bbox]\n",
    "            mask = masks[bbox_i][0]\n",
    "            mask = cv2.resize(mask, (bbox[2]-bbox[0]+1, bbox[3]-bbox[1]+1))\n",
    "            mask = mask > NN_THRESHOLD\n",
    "            \n",
    "            im_mask = np.zeros((test_image.shape[0], test_image.shape[1]), dtype=np.uint8)\n",
    "            x_0 = max(bbox[0], 0)\n",
    "            x_1 = min(bbox[2] + 1, test_image.shape[1])\n",
    "            y_0 = max(bbox[1], 0)\n",
    "            y_1 = min(bbox[3] + 1, test_image.shape[0])\n",
    "            mask_y_0 = max(y_0 - bbox[1], 0)\n",
    "            mask_y_1 = mask_y_0 + y_1 - y_0\n",
    "            mask_x_0 = max(x_0 - bbox[0], 0)\n",
    "            mask_x_1 = mask_x_0 + x_1 - x_0\n",
    "            \n",
    "            im_mask[y_0:y_1, x_0:x_1] = mask[\n",
    "                mask_y_0 : mask_y_1, mask_x_0 : mask_x_1\n",
    "            ]\n",
    "            \n",
    "            green_masks[:,:,0][im_mask>0] = 61\n",
    "            green_masks[:,:,1][im_mask>0] = 142\n",
    "            green_masks[:,:,2][im_mask>0] = 48\n",
    "    \n",
    "    test_image = cv2.addWeighted(test_image, 0.6, green_masks, 0.4, 0)\n",
    "    cv2.imwrite(IMAGE_DIR + f'/final/maskrcnn_{int(NN_THRESHOLD*10)}_' + image_path, cv2.cvtColor(test_image, cv2.COLOR_RGB2BGR))\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    _ = ax.imshow(test_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_iou = []\n",
    "total_granules_det = []\n",
    "\n",
    "for image_i, image_path in enumerate(tqdm(processed_data['image_path'])):\n",
    "    test_image = cv2.imread(image_path)\n",
    "    test_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)\n",
    "    gt_mask = processed_data['semantic_masks'][image_i]\n",
    "\n",
    "    onnx_input = onnx_preprocessing(test_image, image_size=(480, 480))\n",
    "    onnx_input = np.concatenate([onnx_input] * BATCH_SIZE)\n",
    "    ort_inputs = {ort_session.get_inputs()[0].name: onnx_input}\n",
    "    boxes_scores, labels, masks = ort_session.run(None, ort_inputs)\n",
    "\n",
    "    bboxes = boxes_scores[0,:,:4] # raw bounding boxes\n",
    "    scores = boxes_scores[0,:,4]   # scores\n",
    "    labels = labels[0,:]           # raw labels\n",
    "    masks = np.transpose(masks, [1, 0, 2, 3])\n",
    "\n",
    "    pr_mask = np.zeros(test_image.shape[:2], dtype=np.uint8)\n",
    "    for bbox_i, bbox in enumerate(bboxes):\n",
    "        if scores[bbox_i] >= NN_THRESHOLD:\n",
    "            bbox = [int(b) for b in bbox]\n",
    "            mask = masks[bbox_i][0]\n",
    "            mask = cv2.resize(mask, (bbox[2]-bbox[0]+1, bbox[3]-bbox[1]+1))\n",
    "            mask = mask > NN_THRESHOLD\n",
    "\n",
    "            im_mask = np.zeros((test_image.shape[0], test_image.shape[1]), dtype=np.uint8)\n",
    "            x_0 = max(bbox[0], 0)\n",
    "            x_1 = min(bbox[2] + 1, test_image.shape[1])\n",
    "            y_0 = max(bbox[1], 0)\n",
    "            y_1 = min(bbox[3] + 1, test_image.shape[0])\n",
    "            mask_y_0 = max(y_0 - bbox[1], 0)\n",
    "            mask_y_1 = mask_y_0 + y_1 - y_0\n",
    "            mask_x_0 = max(x_0 - bbox[0], 0)\n",
    "            mask_x_1 = mask_x_0 + x_1 - x_0\n",
    "\n",
    "            im_mask[y_0:y_1, x_0:x_1] = mask[\n",
    "                mask_y_0 : mask_y_1, mask_x_0 : mask_x_1\n",
    "            ]\n",
    "            pr_mask[im_mask>0] = 1\n",
    "\n",
    "    total_granules_det.append(len(bboxes))\n",
    "    total_iou.append(binary_mask_iou(gt_mask, pr_mask))\n",
    "\n",
    "granules_deviation = np.abs((np.array(total_granules_det) - np.array(processed_data['granules_number']))) / np.array(processed_data['granules_number']) * 100\n",
    "granules_detected = (np.array(total_granules_det) / np.array(processed_data['granules_number'])) * 100\n",
    "\n",
    "\n",
    "print(f\"Median and Average IoU for all dataset = {np.median(total_iou)} VS {np.average(total_iou)}, disp = {np.std(total_iou)}\")\n",
    "print(f\"Median and Average granules devianion for all dataset = {np.median(granules_deviation)} VS {np.average(granules_deviation)}, disp = {np.std(granules_deviation)}\")\n",
    "print(f\"Median and Average granules detected for all dataset = {np.median(granules_detected)} VS {np.average(granules_deviation)}, disp = {np.std(granules_detected)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
